{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression\n",
    "\n",
    "## Key Take Aways\n",
    "- Regression is a Supervised Learning with multiple features and a target\n",
    "    - If target is numerical → Regression Analysis\n",
    "    - If target is categorical → Classification\n",
    "\n",
    "- r² and RMSE is used as measure of goodness of the fit. But may not be a measure of goodness of the solution to a _Business Problem_\n",
    "\n",
    "\n",
    "---------------------------------------\n",
    "\n",
    "h08c - Advanced Linear Regression (Notebook)\n",
    "\n",
    "l08 - Lecture\n",
    "        - What is Regression Analysis?\n",
    "        - Regression Models\n",
    "        - Simple Linear Regression Model\n",
    "        - Coefficient of determination (r2) and RMSE – Goodness of the fit\n",
    "        - Multiple Linear Regression\n",
    "\n",
    "l08b - has something to be interpreted.\n",
    "\n",
    "\n",
    "--------------------------------------\n",
    "\n",
    "\n",
    "# Simple Linear Regression\n",
    "\n",
    "Simple Linear regression is: $y = \\beta_0 + \\beta_1x$\n",
    "\n",
    "What does each term represent?\n",
    "- $y$ is the response\n",
    "- $x$ is the feature\n",
    "- $\\beta_0$ is the intercept\n",
    "- $\\beta_1$ is the coefficient for x\n",
    "\n",
    "The _Learning_ is the part of minimizing the sum of squared residuals.\n",
    "\n",
    "![Slope](img/slope_intercept.png)\n",
    "\n",
    "## How well does the model fit the data?\n",
    "The most common way to evaluate the overall fit of a linear model is by the $r^2$. $r^2$ is the proportion of variance explained, meaning the proportion of variance in the observed data that is explained by the model, or the reduction in error over the null model. (The null model just predicts the mean of the observed response, and thus it has an intercept and no slope.)\n",
    "\n",
    "$r^2$ is between 0 and 1, and higher is better because it means that more variance is explained by the model.\n",
    "\n",
    "![r_squared](img/r_squared.png)\n",
    "\n",
    "## Model Evaluation Metrics for Regression\n",
    "To measure *quality of a model* there are 3 types of evaluators. Mean Absolute Error (MAE), Mean Squared Error (MSE) and Root Mean Squared Error (RMSE). MSE is more popular than MAE because MSE \"punishes\" larger errors. But, RMSE is even more popular than MSE because RMSE is interpretable in the \"y\" units. Hint: **Smaller is better**, since all these metrics measure the _Error_.\n",
    "\n",
    "---\n",
    "\n",
    "# Advanced Linear Regression\n",
    "Simple LInear regression can easily be extended to include multiple features. This is then called _multiple linear regression_.\n",
    "\n",
    "$y = \\beta_0 + \\beta_1x_1 + ... + \\beta_nx_n$\n",
    "\n",
    "Each $x$ represents a different feature, and each feature has its own coefficient. In this case:\n",
    "\n",
    "$y = \\beta_0 + \\beta_1 \\times TV + \\beta_2 \\times Radio + \\beta_3 \\times Newspaper$\n",
    "\n",
    "As an example let's say we calculated the following coefficients:  \n",
    "$\\beta_1 = 0.046$  \n",
    "$\\beta_2 = 0.188$  \n",
    "$\\beta_3 = -0.001$  \n",
    "\n",
    "How do we interpret these coefficients? For a given amount of Radio and Newspaper ad spending, an **increase of $1000 in TV ad spending** is associated with an **increase in Sales of 46 widgets**.\n",
    "\n",
    "## Feature Selection\n",
    "\n",
    "Which Features to include? One Idea is → try different models and chec wheather the $r^2$ values goes up when new features are added. One drawback is that $r^2$ will always increase more features are added to the model!\n",
    "\n",
    "A better approach is _train/test split_ or _cross-validation_. Importantly, cross-validation can be applied to any model, whereas the methods described above only apply to linear models. \n",
    "\n",
    "An example would be, using a train/test split on the previous example. Building a Linear Regression Model with all features and one without _Newspapers_. Let's say the outcome is somewhat like\n",
    "\n",
    "**Include Newspaper**: $RMSE = 1.4047; r^2 = 0.896$  \n",
    "**Excluded Newspaper**: $RMSE = 1.3879; r^2 = 0.897$\n",
    "\n",
    "We can see that it makes sense to _not_ include Newspaper - the RMSE goes up and $r^2$ goes down if it is included, so the model without Newspaper is better.\n",
    "\n",
    "### Handling categorical Features with two categories\n",
    "If the categorical feature has only two possibilities like \"large/small\" the data can be represented by a dummy variable _size\\_large_ coded as 0/1.\n",
    "\n",
    "**Interpretation:**  \n",
    "Let's say the following coefficients are the outcome:  \n",
    "$TV = 0.046$  \n",
    "$Radio = 0.188$  \n",
    "$Newspaper = -0.001$  \n",
    "$Size\\_large = 0.057$  \n",
    "\n",
    "The Interpretation for _Size\\_large_ goes as followed: For a given amount of TV/Radio/Newspaper ad spending, being a large market is associated with an average increase in Sales of 57 widgets (as compared to a small market, which is called the baseline level). Reverse Encoding of small/large would simply lead to a negative coefficient, meaning _\"In small markets the sales of widgets would go down by 57 widgets, compared to the baseline (which is now the large market)\"_\n",
    "\n",
    "\n",
    "### Handling categorical Features with more than two categories\n",
    "In case of multiple categorical features, which are not ordered, we'll need to create $k-1$ extra dummy variables. Example, Area has three categories: rural, suburban and urban. The needed dummy variables would for example be, `area_rural` and `area_subruban`. `area_urban` is not needed since that going to be our baseline. Both dummy variables are binary coded, and if both are zero, the baseline holds. \n",
    "\n",
    "**Interpretation:**  \n",
    "$TV = 0.046$  \n",
    "$Radio = 0.188$  \n",
    "$Newspaper = -0.001$  \n",
    "$Size\\_large = 0.077$  \n",
    "$Area\\_suburban = -0.107$  \n",
    "$Area\\_urban = 0.268$  \n",
    "\n",
    "- Holding all other variables fixed, being a **suburban** area is associated with an average **decrease**, in Sales of 107 (as compared to the baseline level, which is rural)\n",
    "- Being an **urban** area is associated with an average **increase** in Sales of 268 widgets (compared to rural)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5 (default, Sep  3 2020, 21:29:08) [MSC v.1916 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "43a903fe36b38cc5bc3c6ffc5b75ae50bab50c8d56bc914f66ebc140ba6708ef"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
